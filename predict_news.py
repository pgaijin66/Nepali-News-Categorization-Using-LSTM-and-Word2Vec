import re
import pickle
import numpy as np
import pandas as pd

import nltk
from nltk.tokenize import word_tokenize

from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
from tensorflow.keras.preprocessing.sequence import pad_sequences
from gensim.models import Word2Vec

nltk.download('punkt')

# Load the model, Word2Vec model, and label encoder
model = load_model('news_classifier_lstm_with_word2vec.h5')

with open('label_encoder.pkl', 'rb') as le_file:
    le = pickle.load(le_file)

word2vec_model = Word2Vec.load("word2vec.model")

# List of Nepali stopwords
nepali_stopwords = [
    'यो', 'छ', 'र', 'थियो', 'हुने', 'मा', 'लाई', 'पनि', 'भएको', 'तथा', 'यस', 'तर', 'कि', 'उनको', 'भन्ने', 
    'को', 'वा', 'रूपमा', 'को', 'नै', 'हो', 'गरेको', 'गर्ने', 'उनले', 'हुन्छ', 'गरे', 'गर्न', 'के', 'संग', 'गरेका',
    'अझै', 'अथवा', 'अर्थात', 'अर्को', 'अगाडी', 'अझ', 'आज', 'अनुसार', 'अन्य', 'अभि', 'अवस्था', 
    'आधा', 'आदि', 'आजकल', 'आपको', 'आफ्नै', 'आफ्नो', 'आफू', 'आफैं', 'आवश्यक', 'इ', 'इन', 
    'उनी', 'उनीहरू', 'उनको', 'उनकै', 'उहाँ', 'ए', 'एक', 'एउटा', 'कति', 'कसैले', 'कहाँ', 'का', 
    'कि', 'कुनै', 'कुनैपनि', 'के', 'कसैलाई', 'कसले', 'को', 'कुन', 'किन', 'कि', 'कृपया', 'खास', 
    'खासगरी', 'गरे', 'गरेको', 'गर्न', 'गरेका', 'गर्ने', 'गरेपछि', 'गर्नु', 'गर्छ', 'गर्छन्', 'गर्नेछन्', 
    'गर्छु', 'गर्दा', 'गर्दछ', 'गर्‍यो', 'गइरहेको', 'गैर', 'घटना', 'चलिरहेको', 'चलाउँछ', 'छ', 
    'छैन', 'चाहन्छ', 'जस्तो', 'जब', 'जसले', 'जसको', 'जहाँ', 'जस्तै', 'जसरी', 'जस', 'जसलाई', 
    'जस्तोसुकै', 'जति', 'जसमा', 'जसले', 'जससँग', 'जुन', 'जुनसुकै', 'जुनसुकै', 'तत्काल', 'तपाईं', 
    'तपाईँ', 'तपाई', 'तपाईंको', 'तपाईँको', 'तपाईको', 'तिमी', 'तिम्रो', 'तिमीले', 'तपाईँले', 'तर', 
    'तथा', 'त्यस', 'त्यसको', 'त्यसैले', 'त्यसो', 'त्यस्तै', 'त्यसपछि', 'तिनका', 'तिनी', 'तिनीहरु', 
    'तिनीहरूको', 'तिनको', 'तिमीहरु', 'त्यो', 'तिनीलाई', 'तपाईंहरू', 'तपाईंले', 'तिमील', 'तिम्रा', 
    'तिनै', 'त्यति', 'थियो', 'थिए', 'थिईन', 'थिएन', 'थियो', 'दुई', 'देखि', 'देखि', 'दिए', 'दिने', 
    'दिएको', 'दिएको', 'देखा', 'दुबै', 'दोश्रो', 'न', 'नभएको', 'नभएपछि', 'नभन्ने', 'नजर', 
    'नजिकै', 'नत्र', 'नयाँ', 'न', 'नहुने', 'नहि', 'निश्चित', 'नया', 'निको', 'निको', 'नियम', 
    'पनि', 'पहिलो', 'परेको', 'पर्याप्त', 'पर्दछ', 'पर्छ', 'परेका', 'पहिले', 'प्राय', 'परेर', 
    'पटक', 'पनि', 'फेरि', 'बनी', 'बनाइ', 'बनाइएको', 'बनाई', 'बनाएको', 'बने', 'बन्न', 'बलियो', 
    'बनाउने', 'बन्दै', 'बस', 'बीच', 'बारे', 'भरि', 'भर', 'भए', 'भएर', 'भएको', 'भन्छ', 'भन्ने', 
    'भएकोले', 'भने', 'भनिन्छ', 'भनेपछि', 'भयो', 'म', 'माथि', 'मात्रै', 'मात्र', 'मेरो', 'मैले', 
    'माझ', 'मात्र', 'मध्ये', 'माथिको', 'मात्र', 'माफ', 'मेरा', 'मै', 'मसँग', 'यति', 'यदि', 'यद्यपि', 
    'यहाँ', 'यही', 'यहीँ', 'यस', 'यसबारे', 'यसको', 'यसले', 'यसमा', 'यस्तो', 'यसै', 'या', 'यो', 
    'र', 'रख', 'रहेका', 'रहेछ', 'रह्यो', 'रहने', 'राखेको', 'रहेको', 'रखिएको', 'राख्ने', 'रहने', 
    'रखिएको', 'राख्न', 'लगायत', 'लिएर', 'लिए', 'लिएपछि', 'लिएर', 'लिन्छ', 'ले', 'लेख', 
    'लेख्ने', 'लागि', 'लगायतका', 'लिएर', 'लाई', 'लिएर', 'लिएर', 'वा', 'शायद', 'सक्छ', 'सक्ने', 
    'सबै', 'सबैका', 'सुरु', 'समेत', 'सधै', 'सँग', 'साथै', 'सक्छन्', 'समय', 'सकिन्छ', 'सक्ने', 
    'सबैभन्दा', 'सम्बन्धित', 'सम्भव', 'सो', 'सोही', 'सक्नु', 'सम्म', 'सय', 'सयौं', 'सवै', 
    'सीधा', 'सम्बन्धित', 'सक्ने', 'सम्पूर्ण', 'सरोकार', 'हाल', 'हालै', 'हालसम्म', 'हिजो', 
    'हुने', 'हुनु', 'हुनसक्छ', 'हुन', 'हुँदै', 'हुनुहुन्छ', 'हुन्छ', 'हुनसक्ने', 'हुने', 
    'हुनेछ', 'हुनुहुन्छ', 'हुन्', 'हेर्न', 'होस्', 'हो', 'होला', 'होइन', 'हुँदा', 'हुँदैन', 
    'हुन्छ', 'हुनु', 'हुनेछन्', 'हुन्छ', 'हुँदैछ', 'हुनुहुन्छ', 'हुँदा', 'हुने', 'हुँदैन'
]

def preprocess_text(text):
    # Remove special characters but keep some punctuation
    text = re.sub(r'[^\w\s।?!]', '', text)
    
    # Tokenize
    tokens = word_tokenize(text.lower())
    
    # Remove Nepali stopwords
    filtered_tokens = [word for word in tokens if word not in nepali_stopwords]
    
    return filtered_tokens

def text_to_sequence(text, word2vec_model, max_len=200):
    tokens = preprocess_text(text)
    sequence = [word2vec_model.wv.key_to_index.get(word, 0) for word in tokens]
    padded_sequence = pad_sequences([sequence], maxlen=max_len)
    return padded_sequence

def classify_new_text(text, model, word2vec_model, le):
    sequence = text_to_sequence(text, word2vec_model)
    prediction = model.predict(sequence)
    predicted_label = np.argmax(prediction, axis=1)
    return le.inverse_transform(predicted_label)[0]

# Provided Nepali text
new_text = """
दैलेखमा पेट्रोलियम अन्वेषण अन्तर्गत ‘ड्रिलिङ’ गर्ने काम १ हजार ३ सय ४० मिटर गहिराइसम्म पुगेको छ ।

खानी तथा भूगर्भ विभागका महानिर्देशक रामप्रसाद घिमिरेका अनुसार आइतबारसम्मको आँकडामा त्यति गहिराइसम्म ड्रिलिङ गरिएको जानकारी आयोजनाले गराएको छ ।

यो आयोजनामा ४ हजारदेखि ४ हजार ५ सय मिटरसम्म गहिराइ ड्रिलिङ गरी अन्वेषणको काम हुनेछ । त्यसपछि यस स्थानमा पेट्रोलियम पदार्थको भण्डार कति छ र त्यसको उत्खनन सम्भावनाबारे अध्ययन गरिने छ ।

सरकारले चालु आर्थिक वर्ष २०८१/८२ भित्रै पेट्रोलियम पदार्थ अन्वेषणको काम सक्ने लक्ष्य राखेको छ । गत आव २०८०/८१ को नीति तथा कार्यक्रममा यस्तो घोषणा गरिएको छ ।

दैलेखमा चिनियाँ सरकारको सहयोगमा पेट्रोलियम पदार्थ अन्वेषणको काम सुरु भएको हो । दैलेखको भैरवी गाउँपालिकामा अन्वेषण साइट छनोट भएको छ ।

चैत २०७२ मा नेपाल र चीनबीच पेट्रोलियम पदार्थ अन्वेषण तथा उत्खननमा सहकार्य गर्ने सहमति भएको थियो । माघ २०७५ मा चीनलाई नेपालका दुई क्षेत्रमा पेट्रोलियम तथा ग्यास खानीबारे विस्तृत अन्वेषण गर्न दिने सम्बन्धी परियोजना स्वीकृत भएको थियो ।
"""

category = classify_new_text(new_text, model, word2vec_model, le)
print(f'The news is classified as: {category}')
